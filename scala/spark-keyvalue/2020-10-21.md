# 2020-10-21

## 目標

- 測試 Scala Linter [scalafix](https://scalacenter.github.io/scalafix/docs/users/installation.html) plugin

## 步驟

- 新增 `addSbtPlugin("ch.epfl.scala" % "sbt-scalafix" % "0.9.21")` 到 `project\plugins.sbt`

```diff
diff --git a/scala/spark-keyvalue/project/plugins.sbt b/scala/spark-keyvalue/project/plugins.sbt
index 72477a2..e9f7f4e 100644
--- a/scala/spark-keyvalue/project/plugins.sbt
+++ b/scala/spark-keyvalue/project/plugins.sbt
@@ -1 +1,2 @@
 addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "0.15.0")
+addSbtPlugin("ch.epfl.scala" % "sbt-scalafix" % "0.9.21")
```

- 測試跑 `sbt "scalafix RemoveUnused"` 時出現以下錯誤訊息，因此需要修改 `build.sbt`

```bash
~/git/snippet/scala/spark-keyvalue$ sbt "scalafix RemoveUnused"
[info] Loading settings for project spark-keyvalue-build from plugins.sbt ...
[info] Loading project definition from /Users/jazzwang/git/snippet/scala/spark-keyvalue/project
[info] Loading settings for project root from build.sbt ...
[info] Set current project to spark-keyvalue (in build file:/Users/jazzwang/git/snippet/scala/spark-keyvalue/)
[warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
[error] (Compile / scalafix) scalafix.sbt.InvalidArgument: The semanticdb-scalac compiler plugin is required to run semantic rules like RemoveUnused.
[error] To fix this problem for this sbt shell session, run `scalafixEnable` and try again.
[error] To fix this problem permanently for your build, add the following settings to build.sbt:
[error] 
[error] inThisBuild(
[error]   List(
[error]     scalaVersion := "2.11.11",
[error]     semanticdbEnabled := true,
[error]     semanticdbVersion := scalafixSemanticdb.revision
[error]   )
[error] )
[error] 
[error] Total time: 9 s, completed Oct 21, 2020 8:55:17 PM
```

- 參考上述錯誤訊息，新增 `inThisBuild(...)` 進 `build.sbt`

```diff
diff --git a/scala/spark-keyvalue/build.sbt b/scala/spark-keyvalue/build.sbt
index c4009e1..f4d3bba 100644
--- a/scala/spark-keyvalue/build.sbt
+++ b/scala/spark-keyvalue/build.sbt
@@ -12,9 +12,18 @@ lazy val root = (project in file("."))
       "org.apache.spark"  %%  "spark-core"    % "2.2.1",
       "org.apache.spark"  %%  "spark-sql"     % "2.2.1",
       scalaTest % Test
-    )
+    ),
+    scalacOptions += "-Ywarn-unused-import" // required by `RemoveUnused` rule
   )
 
+inThisBuild(
+  List(
+    scalaVersion := "2.11.11",
+    semanticdbEnabled := true,
+    semanticdbVersion := "4.1.9"
+  )
+)
+
 // https://stackoverflow.com/questions/24996437/how-to-execute-a-bash-script-as-sbt-task/25005
 import scala.sys.process._
 lazy val distclean = taskKey[Unit]("Clean up temporary files and directories")
```

- ( 2020-10-21 21:19:53 ) 備註：原本定義的 `scalafixSemanticdb.revision` 是 `4.3.22`。可是預設的 maven repo 找不到，所以只好根據 maven repo 手動改成 `4.1.9`
    - 參考文件：https://www.scala-sbt.org/1.x/docs/Resolvers.html

```shell
[error] (update) sbt.librarymanagement.ResolveException: Error downloading org.scalameta:semanticdb-scalac_2.11.11:4.3.22
[error]   Not found
[error]   Not found
[error]   not found: /Users/jazzwang/.ivy2/local/org.scalameta/semanticdb-scalac_2.11.11/4.3.22/ivys/ivy.xml
[error]   not found: https://repo1.maven.org/maven2/org/scalameta/semanticdb-scalac_2.11.11/4.3.22/semanticdb-scalac_2.11.11-4.3.22.pom
[error] Total time: 2 s, completed Oct 21, 2020 9:02:18 P
```

- ( 2020-10-21 21:24:50 ) 刻意在程式碼中加入不需要的 `import java.io._`，然後再跑一次 `sbt "scalafix RemoveUnused"`，結果程式碼就自動移除了不必要的 import

```shell
~/git/snippet/scala/spark-keyvalue$ code src/main/scala/example/Hello.scala 
~/git/snippet/scala/spark-keyvalue$ sbt "scalafix RemoveUnused"
[info] Loading settings for project spark-keyvalue-build from plugins.sbt ...
[info] Loading project definition from /Users/jazzwang/git/snippet/scala/spark-keyvalue/project
[info] Loading settings for project root from build.sbt ...
[info] Set current project to spark-keyvalue (in build file:/Users/jazzwang/git/snippet/scala/spark-keyvalue/)
[info] Compiling 1 Scala source to /Users/jazzwang/git/snippet/scala/spark-keyvalue/target/scala-2.11/classes ...
[warn] /Users/jazzwang/git/snippet/scala/spark-keyvalue/src/main/scala/example/Hello.scala:6:16: Unused import
[warn] import java.io._
[warn]                ^
[warn] one warning found
[info] Running scalafix on 1 Scala sources
[success] Total time: 15 s, completed Oct 21, 2020 9:24:06 PM
```
- ( 2020-10-21 21:32:53 ) 沒特別做設定，再跑 `sbt compile` 的時候也會『**警告**』不需要的 import

```shell
~/git/snippet/scala/spark-keyvalue$ sbt compile
[info] Loading settings for project spark-keyvalue-build from plugins.sbt ...
[info] Loading project definition from /Users/jazzwang/git/snippet/scala/spark-keyvalue/project
[info] Loading settings for project root from build.sbt ...
[info] Set current project to spark-keyvalue (in build file:/Users/jazzwang/git/snippet/scala/spark-keyvalue/)
[info] Executing in batch mode. For better performance use sbt's shell
[info] Compiling 1 Scala source to /Users/jazzwang/git/snippet/scala/spark-keyvalue/target/scala-2.11/classes ...
[warn] /Users/jazzwang/git/snippet/scala/spark-keyvalue/src/main/scala/example/Hello.scala:6:16: Unused import
[warn] import java.io._
[warn]                ^
[warn] one warning found
[success] Total time: 10 s, completed Oct 21, 2020 9:32:28 PM
```

- ( 2020-10-21 21:53:49 ) 調整 `ThisBuild` 的寫法，並嘗試啟用 `scalafixOnCompile` 並加入 `.scalafix.conf` 設定檔

```diff
diff --git a/scala/spark-keyvalue/build.sbt b/scala/spark-keyvalue/build.sbt
index c4009e1..6e4c31e 100644
--- a/scala/spark-keyvalue/build.sbt
+++ b/scala/spark-keyvalue/build.sbt
@@ -4,6 +4,10 @@ ThisBuild / scalaVersion     := "2.11.11"
 ThisBuild / version          := "0.1.0"
 ThisBuild / organization     := "com.example"
 ThisBuild / organizationName := "example"
+ThisBuild / semanticdbEnabled := true
+ThisBuild / semanticdbVersion := "4.1.9"
+ThisBuild / scalafixOnCompile := true
+ThisBuild / scalacOptions     += "-Ywarn-unused-import" // required by `RemoveUnused` rule
 
 lazy val root = (project in file("."))
   .settings(
```


## 參考文件

- https://github.com/mramshaw/Scala-Linters