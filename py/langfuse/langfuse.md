# LangFuse

## 2025-04-25

- 緣起：
  - 一直沒找到怎麼查 Ollama API 收到的 Prompt 是什麼。
  - 好奇 Aider 會送什麼給 Ollama 的 API Server
- 搜尋：
  - `ollama obseravibility`
- 結果：
  - 查到好幾篇文章是使用 LangFuse 來達成 Logging & Observability 的目的
    - 2025-01-25: [LLMOps series — Part 2: Multi-LLM Observability Dashboard (Amazon Bedrock, OLLAMA, OpenAI) with Langfuse](https://medium.com/@srpillai/llmops-series-part-2-multi-llm-observability-dashboard-amazon-bedrock-ollama-openai-with-48622e8f94ce)
    - 2025-01-01: [End-to-End LLM Monitoring, Observability, Evaluation and Calibration — Part 1](https://medium.com/analytics-vidhya/end-to-end-llm-monitoring-observability-evaluation-and-calibration-part-1-1b2d62b71ad6)
  - 官方文件：
    - Trace your local Ollama model with Langfuse
    - https://langfuse.com/docs/integrations/ollama
  - 當然也有類似的產品：
    - https://www.traceloop.com/
      - https://www.traceloop.com/openllmetry/integrations/observability-for-ollama-with-traceloop
    - https://www.langtrace.ai/
      - https://www.langtrace.ai/blog/run-and-debug-your-llm-apps-locally-using-ollama