# Gemini CLI

- Git Repo
  - https://github.com/google-gemini/gemini-cli
- News
  - 2025-06-25: [Gemini CLI: your open-source AI agents](https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/)
  - 2025-06-26: [Gemini CLIï¼šä½ çš„é–‹æº AI ä»£ç†](https://blog.google/intl/zh-tw/products/cloud/gemini-cli-your-open-source-ai-agent/)

## 2025-06-25

- See the news from [LargitData's LinkedIn Post](https://www.linkedin.com/feed/update/urn:li:activity:7343622985636827136/)

> Google ä½ é€™ä¸è¦è‡‰çš„å‚¢ä¼™ï¼Œé€£ Claude Code éƒ½æŠ„ï¼Œä¸éçœ‹åœ¨å…è²»çš„ä»½ä¸Šï¼Œåªå¥½åŸè«’ä½ äº†ï¼ğŸ˜¤
>
> Google å³å°‡æ¨å‡º Gemini CLIï¼Œa.k.a. Claude Code çš„ Gemini ç‰ˆæœ¬ã€‚ğŸš€
>
> ğŸ’° æœ€å¤§è³£é» ï¼Œåªéœ€ä½¿ç”¨ Google å¸³æˆ¶ç™»å…¥ï¼Œå³å¯ç²å¾—ï¼š
>
> - Gemini 2.5 Pro æ¨¡å‹ï¼Œå« 100 è¬ token çš„è¶…å¤§ä¸Šä¸‹æ–‡è¦–çª—
> - æ¯åˆ†é˜ 60 æ¬¡è«‹æ±‚ï¼Œæ¯æ—¥æœ€å¤š 1,000 æ¬¡è«‹æ±‚
>
> ä»£è¡¨å¹¾ä¹å®Œå…¨å…è²»ï¼
>
> â­ Gemini CLI é‚„æä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š
>
> ğŸ§  æ™ºæ…§ç¨‹å¼ç¢¼ç†è§£ï¼šæ·±åº¦ç†è§£ç¨‹å¼ç¢¼ï¼Œæä¾›debugå’Œæœ€ä½³åŒ–å»ºè­°
> ğŸ”§ ç³»çµ±æ•´åˆï¼šé€éè‡ªç„¶èªè¨€ç›´æ¥æ“ä½œæª”æ¡ˆå’ŒåŸ·è¡Œç³»çµ±å‘½ä»¤
> ğŸ” å³æ™‚ç¶²è·¯æœå°‹ï¼šå…§å»º Google æœå°‹åŠŸèƒ½ï¼
> ğŸ›ï¸ é«˜åº¦å¯å®¢è£½åŒ–ï¼šæ”¯æ´MCPã€è‡ªè¨‚æç¤ºå’Œ GEMINI .md (é€£é€™ä¹ŸæŠ„)
> ğŸ¤– è‡ªå‹•åŒ–æ•´åˆï¼šæ”¯æ´éåŒæ­¥å‘¼å«ï¼Œå®Œç¾æ•´åˆç¾æœ‰çš„å·¥ä½œæµç¨‹
>
> å¥½å•¦ï¼Œå¤§å» éƒ½ä¸‹ä¾†å·äº†ï¼ŒçŒœçŒœæˆ‘å€‘çš„ç¨è§’ç¸ Cursor é‚„æœ‰å¤šå°‘å…‰æ™¯å¥½æ´»ï¼Ÿï¼ğŸ˜

- çœ‹èµ·ä¾†è »å€¼å¾—èŠ±é»æ™‚é–“æ¸¬è©¦ä¸€ä¸‹ã€‚

## 2025-07-04

- ( 2025-07-04 12:13:19 )
- åƒè€ƒï¼š
  - 2025-06-27: ğŸŒŸ Gemini CLI åˆæ¢ï¼šè®“ Gemini é€²å…¥ä½ çš„çµ‚ç«¯æ©Ÿ
  - https://vocus.cc/article/685dd5edfd897800010b06d3
- ç’°å¢ƒï¼š
  - Windows 11 Home x86_64
- å®‰è£ï¼š
```bash
~$ npm install -g @google/gemini-cli

added 432 packages in 23s
```
- ç¢ºèªï¼š
```bash
~$ which gemini
/c/Users/jazzw/scoop/apps/nvm/current/nodejs/nodejs/gemini
~$ gemini --help
Options:
  -m, --model                    Model      [string] [default: "gemini-2.5-pro"]
  -p, --prompt                   Prompt. Appended to input on stdin (if any).
                                                                        [string]
  -s, --sandbox                  Run in sandbox?                       [boolean]
      --sandbox-image            Sandbox image URI.                     [string]
  -d, --debug                    Run in debug mode?   [boolean] [default: false]
  -a, --all_files                Include ALL files in context?
                                                      [boolean] [default: false]
      --show_memory_usage        Show memory usage in status bar
                                                      [boolean] [default: false]
  -y, --yolo                     Automatically accept all actions (aka YOLO
                                 mode, see
                                 https://www.youtube.com/watch?v=xvFZjo5PgG0 for
                                 more details)?       [boolean] [default: false]
      --telemetry                Enable telemetry? This flag specifically
                                 controls if telemetry is sent. Other
                                 --telemetry-* flags set specific values but do
                                 not enable telemetry on their own.    [boolean]
      --telemetry-target         Set the telemetry target (local or gcp).
                                 Overrides settings files.
                                              [string] [choices: "local", "gcp"]
      --telemetry-otlp-endpoint  Set the OTLP endpoint for telemetry. Overrides
                                 environment variables and settings files.
                                                                        [string]
      --telemetry-log-prompts    Enable or disable logging of user prompts for
                                 telemetry. Overrides settings files.  [boolean]
  -c, --checkpointing            Enables checkpointing of file edits
                                                      [boolean] [default: false]
  -v, --version                  Show version number                   [boolean]
  -h, --help                     Show help                             [boolean]
~$ gemini -v
0.1.9
```
- å¯¦æ¸¬äº’å‹•ï¼š
  - ![](20250704123324_gemini-cli_websearch_tool.png)
  - ![](20250704121805_gemini-cli_version.png)
  - ![](20250704123413_gemini-cli_tokens.png)
```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  > /tools  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â„¹ Available Gemini CLI tools:

    - ReadFolder
    - ReadFile
    - SearchText
    - FindFiles
    - Edit
    - WriteFile
    - WebFetch
    - ReadManyFiles
    - Shell
    - Save Memory
    - GoogleSearch
```

- åˆæ­¥æ„Ÿæƒ³ï¼š
  - Autocompletion ä¸åƒ Aider å¯ä»¥ç”¨ TAB è‡ªå‹•è£œé½Š `/{command}`ï¼Œä¹Ÿè¨±é‚„æœ‰ç‰¹å®šçš„ hotkey è¦ç ”ç©¶æ–‡ä»¶æ‰æœƒçŸ¥é“ã€‚
  - ç›¸è¼ƒæ–¼ Aiderï¼ŒGemini CLI åªæ”¯æ´å–®ä¸€æ¨¡å‹ã€‚
  - ç›¸è¼ƒæ–¼ Aiderï¼Œç›®å‰ Aider æ¯”è¼ƒç¼ºä¹çš„éƒ¨ä»½æ‡‰è©²å°±æ˜¯ `/tools` è·Ÿ `/mcp` é€™å…©å¡Šå§ï½
    - Tools: é€™éƒ¨ä»½ç†è«–ä¸Šæ‡‰è©²æ˜¯ Model æœ¬èº«æ˜¯å¦æ”¯æ´ `Tool Calling`ï¼Œä½†æˆ‘æœ‰é»ä¸ç¢ºå®šç‚ºä»€éº¼ Gemini 2.5 Pro å¯ä»¥æ˜ç¢ºåˆ—å‡ºå·¥å…·åˆ—è¡¨ã€‚å…¶ä»–æ”¯æ´ Tool çš„æ¨¡å‹(e.g. `Qwen 2.5`)ä¸¦æ²’æœ‰
    - MCP: é›–ç„¶æœ‰äººå·²ç¶“å¯«äº†è®“ Aider æ”¯æ´MCP çš„å¤–æ›ï¼Œä½†é‚„æ˜¯æœŸå¾… Aider æœ‰æœä¸€æ—¥å¯ä»¥æŠŠé€™æ®µè£œèµ·ä¾†ã€‚
  - Aider æœ‰å¯¦ä½œ `cache` ä¾†æ¸›å°‘ token ç”¨é‡ï¼Œgemini-cli çœ‹èµ·ä¾†ä¹Ÿæœ‰å¯¦ä½œé€™ä¸€å¡Šï¼Œä¸é<mark>åƒ…é™æ–¼ API Key èªè­‰ç”¨æˆ¶</mark>ã€‚ç›´æ¥ä½¿ç”¨ Gmail OAuth èªè­‰è·Ÿä½¿ç”¨ Google Code Assistant çš„ç”¨æˆ¶ï¼Œé‚„ä¸æ”¯æ´å¿«å–ç¯€è²»(Token Caching and Cost Optimization)ã€‚ç•¶ç„¶ç§‘æŠ€å¤§å» çŸ­æœŸå…§æ‡‰è©²å°±æ˜¯ç ¸éŒ¢é¤Šç”¨é‡ã€‚å…ˆé–‹æ”¾å…è²»ä½¿ç”¨ï¼Œé¤Šå¥—æ®ºç­–ç•¥ã€‚æ—¥ä¹…è¦‹äººå¿ƒï¼Œä½¿ç”¨è€…æœƒç”¨è…³æŠ•ç¥¨ã€‚
    - åƒè€ƒï¼š
      - https://github.com/google-gemini/gemini-cli/blob/main/docs/troubleshooting.md
      > Q: Why don't I see <mark>cached token</mark> counts in my stats output?
      > A: Cached token information is only displayed when cached tokens are being used. <mark>This feature is available for **API key** users (Gemini API key or Vertex AI) but not for **OAuth** users (Google Personal/Enterprise accounts) at this time</mark>, as the Code Assist API does not support cached content creation. You can still view your total token usage with the `/stats` command.
      - https://github.com/google-gemini/gemini-cli/blob/main/docs/telemetry.md
      > gemini_cli.api_response: This event occurs upon receiving a response from Gemini API.
      > - Attributes:
      >   - model
      >     - status_code
      >     - duration_ms
      >     - error (optional)
      >     - input_token_count
      >     - output_token_count
      >     - <mark>cached_content_token_count</mark>
      >     - thoughts_token_count
      >     - tool_token_count
      >     - response_text (if applicable)
      - https://github.com/google-gemini/gemini-cli/blob/main/docs/cli/token-caching.md
      > **Token Caching and Cost Optimization**
      > Gemini CLI automatically optimizes API costs through token caching when using API key authentication (Gemini API key or Vertex AI). This feature reuses previous system instructions and context to reduce the number of tokens processed in subsequent requests.
      >
      > - **Token caching is available for:**
      >   - API key users (Gemini API key)
      >   - Vertex AI users (with project and location setup)
      >
      > - **Token caching is not available for:**
      >   - OAuth users (Google Personal/Enterprise accounts) - the Code Assist API does not support cached content creation at this time
      >
      > You can view your token usage and cached token savings using the `/stats` command. When cached tokens are available, they will be displayed in the stats output.
- å•†æ¥­ç­–ç•¥è§€å¯Ÿï¼š
  - `Github Copilot` vs `Google Code Assistant`
  - `Claude Code` vs `Gemini CLI`

## 2025-08-20

- Gemini CLI for GitHub Actions
  - https://www.linkedin.com/feed/update/urn:li:activity:7358848236998041601/
- 2025-08-06:
  - Meet your new AI coding teammate: Gemini CLI GitHub Actions
  - https://blog.google/technology/developers/introducing-gemini-cli-github-actions/
  - https://github.com/google-github-actions/run-gemini-cli

## 2025-08-21

- 2025-06-29:
  - Conquering Google Login for Gemini CLI on Headless Servers
  - https://medium.com/@fourdollars/conquering-google-login-for-gemini-cli-on-headless-servers-3e9d2649790f
- 2025-07-05:
  - Gemini CLI in GCP Cloud Shell with Google login å°è¨˜
  - https://sakananote2.blogspot.com/2025/07/gemini-cli-in-gcp-cloud-shell-with.html

## 2025-08-26

- çœ‹åˆ¥äººæ¯”è¼ƒ `Claude Code` è·Ÿ `Gemini CLI`
- è§€é»ä¸€ï¼šè®“ `Claude Code` è·Ÿ `Gemini CLI` åˆä½œ
  - æœ‰é»é¡ä¼¼äº¤å‰è©°å•ï¼Œå…ˆæŠŠéœ€æ±‚å®šç¾©æ¸…æ¥šä»¥å¾Œï¼Œå†è®“ä»–å€‘å¯¦ä½œï¼Œä¸¦äº’ç›¸ Code Reviewã€‚
  - æœ‰äººå»ºè­°ç”¨ MCP çš„æ–¹å¼ä¾†è®“å…©å€‹æ¨¡å‹åˆä½œï¼Œè »æœ‰è¶£çš„ä½œæ³•ã€‚
  - Jun 27, 2025-06-27:
    - https://blog.metamirror.io/claude-code-v-gemini-cli-e144feafbcf2
- è§€é»äºŒï¼š`Claude Code` çš„ Code Quality è·Ÿ User Experience æ¯”è¼ƒå¥½ã€‚
  - 2025-07-02:
    - https://composio.dev/blog/gemini-cli-vs-claude-code-the-better-coding-agent
    - (åŒæ–‡è½‰è²¼) https://dev.to/composiodev/i-burnt-10m-tokens-to-compare-claude-code-and-gemini-cli-here-is-what-i-found-out-2e9k
- è§€é»ä¸‰ï¼š`Gemini CLI` çš„ Context Windows æ¯”è¼ƒå¤§ï¼Œæ”¯æ´ã€Œå¤šæ¨¡æ…‹ã€ï¼Œå·²ç¶“æ•´åˆ MCP Toolï¼Œå…è²»é¡åº¦
  - 2025-07-09:
    - Claude Code vs Gemini CLI: Which Oneâ€™s the Real Dev Co-Pilot?
    - https://milvus.io/blog/claude-code-vs-gemini-cli-which-ones-the-real-dev-co-pilot.md
  - **3\. Code Quality vs Speed**

    | **Feature** | **Gemini CLI** | **Claude Code** | **Notes** |
    | --- |  --- |  --- |  --- |
    | **Coding speed** | 8.5/10 | 7.2/10 | Gemini generates code faster |
    | **Coding quality** | 7.8/10 | 9.1/10 | Claude generates higher quality code |
    | **Error handling** | 7.5/10 | 8.8/10 | Claude is better at error handling |
    | **Context understanding** | 9.2/10 | 7.9/10 | Gemini has longer memory |
    | **Multilingual support** | 8.9/10 | 8.5/10 | Both are excellent |

  - **6\. Feature Comparison Overview**

    | **Feature** | **Claude Code** | **Gemini CLI** |
    | --- |  --- |  --- |
    | Context Window Length | 200K tokens | 1M tokens |
    | Multimodal Support | Limited | Powerful (images, PDFs, etc.) |
    | Code Understanding | Excellent | Excellent |
    | Tool Integration | Basic | Rich (MCP Servers) |
    | Security | Enterprise-grade | Standard |
    | Free Requests | Limited | 60/min, 1000/day |
  - 2025-07-09:
    - Gemini-CLI vs Claude-Codeï¼šå·¥ä½œæµæ™‚ä»£çš„é–‹ç«¯
    - https://hkmci.com/zh-hant/blog/gemini-cli-vs-claude-code-workflow-era/?nab=0
    - åœ¨æ·±å…¥æ¯”è¼ƒå‰ï¼Œæˆ‘å€‘å…ˆé‡æ¸…ä¸€å€‹é—œéµå·®ç•°ï¼š
      - `Claude Code` æ˜¯ä¸€æ¬¾å°ˆæ³¨æ–¼ç·¨ç¨‹æ”¯æ´çš„<mark>ä»£ç†å¼ç·¨ç¢¼å·¥å…·ï¼ˆAgentic **Coding** Toolï¼‰</mark>ï¼Œæ ¸å¿ƒèƒ½åŠ›æ˜¯åœ¨å‘½ä»¤åˆ—ä»‹é¢ï¼ˆCLIï¼ŒCommand Line Interfaceï¼‰ä¸­å”åŠ©ä½¿ç”¨è€…æ’°å¯«èˆ‡å„ªåŒ–ç¨‹å¼ç¢¼ï¼Œæœ€ç›´æ¥çš„è·¯å¾‘å°±èƒ½å°‡æç¤ºè©ï¼ˆpromptï¼‰å‚³é€çµ¦æ¨¡å‹ã€‚
      - `Gemini CLI` æ“æœ‰ Gemini 2.5 Pro çš„å¼·å¤§æ¨¡å‹ï¼Œä¹Ÿèƒ½åœ¨çµ‚ç«¯æ©Ÿï¼ˆterminalï¼‰æ“ä½œ AI å”åŠ©ç·¨ç¢¼ã€ç·¨ç¨‹ï¼Œä½†å®ƒçš„å®šä½ç‚º<mark>ä»£ç†å¼å·¥ä½œæµå·¥å…·ï¼ˆAgentic **Workflow** Toolï¼‰</mark>ï¼Œç¨‹å¼æ’°å¯«åªæ˜¯å…¶çœ¾å¤šèƒ½åŠ›ä¸­çš„ä¸€ç’°ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå®ƒèƒ½å”åŠ©ä½¿ç”¨è€…è‡ªå‹•åŒ–è¤‡é›œçš„æ—¥å¸¸å·¥ä½œæµç¨‹ï¼Œæˆç‚ºå…¨é¢çš„æ•¸ä½åŠ©ç†ã€‚

## 2025-10-09

- ç·£èµ·ï¼š
  - å› ç‚ºçœ‹åˆ° Github Spec Kit æ”¯æ´ Claude Code, Gemini CLI å»æ²’æœ‰æ”¯æ´ Aider
  - å›åˆ°å…ˆå‰æƒ³ç ”ç©¶ Gemini CLI æ˜¯å¦æ”¯æ´å…¶ä»– Local LLM
- ç›¸é—œè¨è«–ï¼š
  - Open AI API compatible ? #1974
    - https://github.com/google-gemini/gemini-cli/discussions/1974
      - https://huggingface.co/engineofperplexity/gemini-openai-proxy/tree/main
      - https://docs.litellm.ai/docs/tutorials/litellm_gemini_cli
      - https://github.com/acoliver/llxprt-code
  - Use with any OpenAI compatible API model, including local models #2665
    - https://github.com/google-gemini/gemini-cli/issues/2665
  - Add support for local/offline language models (Ollola, LM Studio, etc.) #5938
    - https://github.com/google-gemini/gemini-cli/issues/5938
- åˆæ­¥çµè«–ï¼š
  - <mark>Gemini CLI é‡å° Gemini æ¨¡å‹åšå„ªåŒ–</mark>
  - çœ‹åˆ°ä¸€å€‹ Workaround æ˜¯è¨­å®šç’°å¢ƒè®Šæ•¸
    - https://github.com/google-gemini/gemini-cli/issues/2665#issuecomment-3020545758

## 2025-10-13

- Gemini for Google Cloud > Documentation > Guides > Gemini CLI
  - https://cloud.google.com/gemini/docs/codeassist/gemini-cli
- Hands-on with Gemini CLI
  - https://codelabs.developers.google.com/gemini-cli-hands-on

```mermaid
flowchart LR
    A[Gemini CLI] -->|Fork| B(Qwen Code)
    A -->|Fork| C(llxprt-code)
    B -->|Support| D(Qwen3 Coder)
    C -->|Support| D(Qwen3 Coder)
    C -->|Support| E(OpenAI GPT-OSS)
    A --> F(Gemini-OpenAI Proxy)
    F --> G(OpenAI)
    A --> H(LiteLLM) --> I(any model, but have compatibility issues)
    C --> J(OpenAI o3)
    C --> K(Anthropic Claude)
    C --> L(OpenRouter)
    C --> M(Fireworks)
    C --> N(Local Models, e.g. serve by Ollama)
```

## 2025-10-27

- ç·£èµ·ï¼š
  - æƒ³çŸ¥é“ Gemini CLI æ˜¯å¦é¡ä¼¼ Aider æœƒæŠŠ Chat History å­˜èµ·ä¾†ï¼Ÿ
- æ–¹æ³•ï¼š
  - å• DeepWiki
  - https://deepwiki.com/search/where-did-gemini-cli-store-his_fd93f653-8a88-40e4-bf00-de9203676ca4?mode=fast
<table><tr><td>Q:</td><td>
<!-- add your Prompt bellow-->
where did gemini cli store history?
</td></tr><tr><td>A:</td><td>
<!-- add Chatbot Response bellow-->
The Gemini CLI stores history in two different locations depending on the type of history:

## Shell Command History

Shell commands executed via the `!` prefix or shell mode are stored in a project-specific directory: [1](#0-0) 

**Location:** `~/.gemini/tmp/<project_hash>/shell_history` [1](#0-0) 

The `<project_hash>` is a unique identifier generated from your project's root path, which prevents conflicts between different projects. [1](#0-0) 

## Chat Conversation History

Chat checkpoints saved via the `/chat save` command are stored in: [2](#0-1) 

**Default locations:**
- Linux/macOS: `~/.gemini/tmp/<project_hash>/`
- Windows: `C:\Users\<YourUsername>\.gemini\tmp\<project_hash>\` [2](#0-1) 

When you run `/chat list`, the CLI scans these specific directories to find available checkpoints. [2](#0-1) 

## Notes

These manually saved chat checkpoints are different from automatic checkpoints created before file modifications (which are covered in the Checkpointing documentation). [3](#0-2)  The shell command history is managed separately and persists across sessions for each project.<cite />

Wiki pages you might want to explore:
- [Tools and File Operations (google-gemini/gemini-cli)](/wiki/google-gemini/gemini-cli#3.3)

### Citations

**File:** docs/get-started/configuration.md (L581-584)
```markdown
- **Location:** `~/.gemini/tmp/<project_hash>/shell_history`
  - `<project_hash>` is a unique identifier generated from your project's root
    path.
  - The history is stored in a file named `shell_history`.
```

**File:** docs/cli/commands.md (L29-34)
```markdown
      - **Details on Checkpoint Location:** The default locations for saved chat
        checkpoints are:
        - Linux/macOS: `~/.gemini/tmp/<project_hash>/`
        - Windows: `C:\Users\<YourUsername>\.gemini\tmp\<project_hash>\`
        - When you run `/chat list`, the CLI only scans these specific
          directories to find available checkpoints.
```

**File:** docs/cli/commands.md (L35-38)
```markdown
        - **Note:** These checkpoints are for manually saving and resuming
          conversation states. For automatic checkpoints created before file
          modifications, see the
          [Checkpointing documentation](../cli/checkpointing.md).
```
</td></tr></table>
<table><tr><td>Q:</td><td>
<!-- add your Prompt bellow-->
can gemini cli output to stdout?
</td></tr><tr><td>A:</td><td>
<!-- add Chatbot Response bellow-->
Yes, Gemini CLI can output to stdout, particularly in **headless/non-interactive mode**. [1](#1-0) 

## How It Works

When you run Gemini CLI with the `--prompt` flag or pipe input via stdin, it operates in non-interactive mode and writes responses directly to stdout: [2](#1-1) 

```bash
gemini --prompt "What is machine learning?"
# or
echo "Explain this code" | gemini
```

The implementation in `runNonInteractive()` writes content events directly to `process.stdout`: [3](#1-2) 

## Output Formats

You have two output format options:

### 1. Text Output (Default)
Standard human-readable output written directly to stdout as the model generates it: [3](#1-2) 

### 2. JSON Output
Structured output with response, statistics, and metadata, buffered and written once at the end: [4](#1-3) 

You can enable JSON output with:
```bash
gemini -p "Your prompt" --output-format json
```

The JSON format includes the response text, model usage stats, tool execution metrics, and error information if applicable. [5](#1-4) 

## Configuration

The output format can be configured via:
- Command-line flag: `--output-format <format>` (values: `text` or `json`) [6](#1-5) 
- Settings file: `output.format` setting [7](#1-6) 

## Notes

The stdout output is designed to be pipe-friendly and handles EPIPE errors gracefully when the receiving process closes early. [8](#1-7)  This makes it suitable for scripting, automation, and integration with other command-line tools.<cite />

Wiki pages you might want to explore:
- [Tools and File Operations (google-gemini/gemini-cli)](/wiki/google-gemini/gemini-cli#3.3)

### Citations

**File:** docs/cli/headless.md (L1-6)
```markdown
# Headless Mode

Headless mode allows you to run Gemini CLI programmatically from command line
scripts and automation tools without any interactive UI. This is ideal for
scripting, automation, CI/CD pipelines, and building AI-powered tools.

```

**File:** docs/cli/headless.md (L45-57)
```markdown
Use the `--prompt` (or `-p`) flag to run in headless mode:

```bash
gemini --prompt "What is machine learning?"
```

### Stdin Input

Pipe input to Gemini CLI from your terminal:

```bash
echo "Explain this code" | gemini
```
```

**File:** docs/cli/headless.md (L90-134)
```markdown
The JSON output follows this high-level structure:

```json
{
  "response": "string", // The main AI-generated content answering your prompt
  "stats": {
    // Usage metrics and performance data
    "models": {
      // Per-model API and token usage statistics
      "[model-name]": {
        "api": {
          /* request counts, errors, latency */
        },
        "tokens": {
          /* prompt, response, cached, total counts */
        }
      }
    },
    "tools": {
      // Tool execution statistics
      "totalCalls": "number",
      "totalSuccess": "number",
      "totalFail": "number",
      "totalDurationMs": "number",
      "totalDecisions": {
        /* accept, reject, modify, auto_accept counts */
      },
      "byName": {
        /* per-tool detailed stats */
      }
    },
    "files": {
      // File modification statistics
      "totalLinesAdded": "number",
      "totalLinesRemoved": "number"
    }
  },
  "error": {
    // Present only when an error occurred
    "type": "string", // Error type (e.g., "ApiError", "AuthError")
    "message": "string", // Human-readable error description
    "code": "number" // Optional error code
  }
}
```
```

**File:** packages/cli/src/nonInteractiveCli.ts (L52-58)
```typescript
      // Handle EPIPE errors when the output is piped to a command that closes early.
      process.stdout.on('error', (err: NodeJS.ErrnoException) => {
        if (err.code === 'EPIPE') {
          // Exit gracefully if the pipe is closed.
          process.exit(0);
        }
      });
```

**File:** packages/cli/src/nonInteractiveCli.ts (L126-131)
```typescript
          if (event.type === GeminiEventType.Content) {
            if (config.getOutputFormat() === OutputFormat.JSON) {
              responseText += event.value;
            } else {
              process.stdout.write(event.value);
            }
```

**File:** packages/cli/src/nonInteractiveCli.ts (L183-189)
```typescript
          if (config.getOutputFormat() === OutputFormat.JSON) {
            const formatter = new JsonFormatter();
            const stats = uiTelemetryService.getMetrics();
            process.stdout.write(formatter.format(responseText, stats));
          } else {
            process.stdout.write('\n'); // Ensure a final newline
          }
```

**File:** docs/get-started/configuration.md (L128-131)
```markdown
- **`output.format`** (string):
  - **Description:** The format of the CLI output.
  - **Default:** `"text"`
  - **Values:** `"text"`, `"json"`
```

**File:** docs/get-started/configuration.md (L715-722)
```markdown
- **`--output-format <format>`**:
  - **Description:** Specifies the format of the CLI output for non-interactive
    mode.
  - **Values:**
    - `text`: (Default) The standard human-readable output.
    - `json`: A machine-readable JSON output.
  - **Note:** For structured output and scripting, use the
    `--output-format json` flag.
```

</td></tr></table>

## 2025-11-16

- 2025-10-22
  - Gemini CLI Tips & Tricks
  - https://addyo.substack.com/p/gemini-cli-tips-and-tricks
  > ~30 pro-tips for effectively using Gemini CLI for agentic coding
- 2025-10-29
  - Introducing the Jules extension for Gemini CLI
  - https://developers.googleblog.com/en/introducing-the-jules-extension-for-gemini-cli/
- 2025-10-31
  - BigQuery Data Analytics with Gemini CLI â€” Part 1
  - https://medium.com/google-cloud/bigquery-data-analytics-with-gemini-cli-part-1-bb692697016a
