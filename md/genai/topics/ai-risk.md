# AI Risk

- 2024-08-04: [Many safety evaluations for AI models have significant limitations 許多針對人工智慧模型的安全評估都存在著很大的局限性](https://techcrunch.com/2024/08/04/many-safety-evaluations-for-ai-models-have-significant-limitations/)

- 2024-08-14: [MIT researchers release a repository of AI risks](https://techcrunch.com/2024/08/14/mit-researchers-release-a-repository-of-ai-risks/)
  - https://airisk.mit.edu/

> The researchers found that the third-party frameworks they canvassed mentioned certain risks more often than others. For example, over 70% of the frameworks included the <mark>privacy and security implications of AI</mark>, whereas only 44% covered <mark>misinformation</mark>. And while over 50% discussed the forms of <mark>discrimination and misrepresentation</mark> that AI could perpetuate, only 12% talked about “pollution of the information ecosystem” — i.e. the increasing volume of AI-generated spam.

>> 研究人員發現，他們所調查的第三方框架比其他框架更頻繁地提到某些風險。例如，超過 70% 的框架涵蓋了人工智慧的<mark>隱私和安全影響</mark>，而只有 44% 的框架涵蓋了<mark>錯誤訊息</mark>。雖然超過 50% 的人討論了人工智慧可能造成的<mark>歧視和虛假陳述</mark>，但只有 12% 的人談到了「資訊生態系統的污染」——即人工智慧產生的垃圾郵件數量的增加。

- [The Global Security Risks of Open-Source AI Models](https://www.globalcenter.ai/analysis/articles/the-global-security-risks-of-open-source-ai-models)

## 2025

- 2025-05-07: [OpenAI宣佈開源轉型：解析帶給AI產業的創新啟示與風險](https://blog.starrocket.io/posts/openai-open-source-shift-risks-opportunities/)
  - 2025-05-05: https://openai.com/index/evolving-our-structure/
- 2025-05-08: [Are Chinese open-weights Models a Hidden Security Risk? 中國公開權重模型是否有安全隱憂？](https://open.substack.com/pub/gradientflow/p/are-chinese-open-weights-models-a)