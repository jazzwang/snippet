# AI Risk

- 2024-08-14: [MIT researchers release a repository of AI risks](https://techcrunch.com/2024/08/14/mit-researchers-release-a-repository-of-ai-risks/)
  - https://airisk.mit.edu/

> The researchers found that the third-party frameworks they canvassed mentioned certain risks more often than others. For example, over 70% of the frameworks included the <mark>privacy and security implications of AI</mark>, whereas only 44% covered <mark>misinformation</mark>. And while over 50% discussed the forms of <mark>discrimination and misrepresentation</mark> that AI could perpetuate, only 12% talked about “pollution of the information ecosystem” — i.e. the increasing volume of AI-generated spam.

>> 研究人員發現，他們所調查的第三方框架比其他框架更頻繁地提到某些風險。例如，超過 70% 的框架涵蓋了人工智慧的<mark>隱私和安全影響</mark>，而只有 44% 的框架涵蓋了<mark>錯誤訊息</mark>。雖然超過 50% 的人討論了人工智慧可能造成的<mark>歧視和虛假陳述</mark>，但只有 12% 的人談到了「資訊生態系統的污染」——即人工智慧產生的垃圾郵件數量的增加。

- 2025-05-08: [Are Chinese open-weights Models a Hidden Security Risk? 中國公開權重模型是否有安全隱憂？](https://open.substack.com/pub/gradientflow/p/are-chinese-open-weights-models-a)